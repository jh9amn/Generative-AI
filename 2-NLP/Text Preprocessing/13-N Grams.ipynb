{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79fa51d4-c851-42d0-834c-663446cd0204",
   "metadata": {},
   "source": [
    "\n",
    "# 🧩 N-Gram Representation with Binary Encoding (Unigram → 4-Gram)\n",
    "\n",
    "## 📘 What is an N-Gram?\n",
    "\n",
    "An **N-gram** is a sequence of **N consecutive words** in a text.  \n",
    "They help capture **context**, **patterns**, and **relationships** between words in Natural Language Processing (NLP).\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Example Sentence\n",
    "\n",
    "> **Sentence:** `I love natural language processing`\n",
    "\n",
    "---\n",
    "\n",
    "## 🔢 Step 1: Generate N-Grams\n",
    "\n",
    "| Type | N | Extracted Tokens |\n",
    "|------|---|------------------|\n",
    "| **Unigram** | 1 | ['I', 'love', 'natural', 'language', 'processing'] |\n",
    "| **Bigram** | 2 | ['I love', 'love natural', 'natural language', 'language processing'] |\n",
    "| **Trigram** | 3 | ['I love natural', 'love natural language', 'natural language processing'] |\n",
    "| **4-gram** | 4 | ['I love natural language', 'love natural language processing'] |\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Step 2: Represent N-Grams in Binary Form\n",
    "\n",
    "Let’s consider **two sentences**:\n",
    "1. **S1:** `I love natural language processing`  \n",
    "2. **S2:** `I love coding in python`\n",
    "\n",
    "We’ll now represent N-grams using **binary encoding (0 and 1)** —  \n",
    "`1` means the N-gram appears in the sentence, `0` means it doesn’t.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 1️⃣ Unigram Binary Representation\n",
    "\n",
    "| Unigram | S1 | S2 |\n",
    "|----------|----|----|\n",
    "| I | 1 | 1 |\n",
    "| love | 1 | 1 |\n",
    "| natural | 1 | 0 |\n",
    "| language | 1 | 0 |\n",
    "| processing | 1 | 0 |\n",
    "| coding | 0 | 1 |\n",
    "| in | 0 | 1 |\n",
    "| python | 0 | 1 |\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 2️⃣ Bigram Binary Representation\n",
    "\n",
    "| Bigram | S1 | S2 |\n",
    "|---------|----|----|\n",
    "| I love | 1 | 1 |\n",
    "| love natural | 1 | 0 |\n",
    "| natural language | 1 | 0 |\n",
    "| language processing | 1 | 0 |\n",
    "| love coding | 0 | 1 |\n",
    "| coding in | 0 | 1 |\n",
    "| in python | 0 | 1 |\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 3️⃣ Trigram Binary Representation\n",
    "\n",
    "| Trigram | S1 | S2 |\n",
    "|----------|----|----|\n",
    "| I love natural | 1 | 0 |\n",
    "| love natural language | 1 | 0 |\n",
    "| natural language processing | 1 | 0 |\n",
    "| I love coding | 0 | 1 |\n",
    "| love coding in | 0 | 1 |\n",
    "| coding in python | 0 | 1 |\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 4️⃣ 4-Gram Binary Representation\n",
    "\n",
    "| 4-Gram | S1 | S2 |\n",
    "|--------|----|----|\n",
    "| I love natural language | 1 | 0 |\n",
    "| love natural language processing | 1 | 0 |\n",
    "| I love coding in | 0 | 1 |\n",
    "| love coding in python | 0 | 1 |\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Step 3: Python Implementation\n",
    "\n",
    "### ✅ Using `CountVectorizer` (Scikit-learn)\n",
    "```python\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sentences = [\n",
    "    \"I love natural language processing\",\n",
    "    \"I love coding in python\"\n",
    "]\n",
    "\n",
    "# Generate Unigram to 4-gram binary features\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 4), binary=True)\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "\n",
    "print(\"Features (N-grams):\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(\"\\nBinary Representation:\\n\", X.toarray())\n",
    "````\n",
    "\n",
    "**Output (Example):**\n",
    "\n",
    "```\n",
    "Features (N-grams): \n",
    "['coding' 'coding in' 'coding in python' 'i' 'i love' 'i love coding' \n",
    " 'i love coding in' 'i love natural' 'in' 'in python' 'language' \n",
    " 'language processing' 'love' 'love coding' 'love coding in' \n",
    " 'love coding in python' 'love natural' 'love natural language' \n",
    " 'love natural language processing' 'natural' 'natural language' \n",
    " 'natural language processing' 'processing' 'python']\n",
    "\n",
    "Binary Representation:\n",
    "[[0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0]\n",
    " [1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1]]\n",
    "```\n",
    "\n",
    "💡 Each **row** corresponds to a sentence, and each **column** corresponds to an N-gram.\n",
    "`1` = present, `0` = absent.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Manual Implementation (Without Libraries)\n",
    "\n",
    "```python\n",
    "def generate_ngrams(words, n):\n",
    "    return [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "\n",
    "sentences = [\n",
    "    \"I love natural language processing\",\n",
    "    \"I love coding in python\"\n",
    "]\n",
    "\n",
    "# Extract all N-grams (1 to 4)\n",
    "all_ngrams = set()\n",
    "for s in sentences:\n",
    "    words = s.split()\n",
    "    for n in range(1, 5):  # 1 to 4\n",
    "        ngrams = generate_ngrams(words, n)\n",
    "        all_ngrams.update(ngrams)\n",
    "\n",
    "all_ngrams = sorted(list(all_ngrams))\n",
    "\n",
    "# Binary matrix\n",
    "binary_matrix = []\n",
    "for s in sentences:\n",
    "    words = s.split()\n",
    "    sentence_ngrams = []\n",
    "    for n in range(1, 5):\n",
    "        sentence_ngrams += generate_ngrams(words, n)\n",
    "    row = [1 if gram in sentence_ngrams else 0 for gram in all_ngrams]\n",
    "    binary_matrix.append(row)\n",
    "\n",
    "print(\"All N-grams (1 to 4):\")\n",
    "print(all_ngrams)\n",
    "print(\"\\nBinary Matrix:\")\n",
    "for row in binary_matrix:\n",
    "    print(row)\n",
    "```\n",
    "\n",
    "**Output Example:**\n",
    "\n",
    "```\n",
    "All N-grams (1 to 4):\n",
    "['I', 'I love', 'I love coding', 'I love coding in', 'I love natural', \n",
    " 'I love natural language', 'I love natural language processing', \n",
    " 'coding', 'coding in', 'coding in python', 'in', 'in python', \n",
    " 'language', 'language processing', 'love', 'love coding', 'love coding in', \n",
    " 'love coding in python', 'love natural', 'love natural language', \n",
    " 'love natural language processing', 'natural', 'natural language', \n",
    " 'natural language processing', 'processing', 'python']\n",
    "\n",
    "Binary Matrix:\n",
    "[1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0]\n",
    "[1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Step 4: Visual Summary\n",
    "\n",
    "| N-Gram      | Captures                | Example                       |\n",
    "| ----------- | ----------------------- | ----------------------------- |\n",
    "| **Unigram** | Single words            | `[\"I\", \"love\"]`               |\n",
    "| **Bigram**  | Pair of words           | `[\"I love\", \"love natural\"]`  |\n",
    "| **Trigram** | Three consecutive words | `[\"I love natural\"]`          |\n",
    "| **4-gram**  | Four consecutive words  | `[\"I love natural language\"]` |\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Step 5: Applications\n",
    "\n",
    "* ✅ **Text Prediction** (keyboard suggestions)\n",
    "* ✅ **Spam Detection** (\"free money\", \"win prize\")\n",
    "* ✅ **Machine Translation**\n",
    "* ✅ **Search Engines** (phrase-based queries)\n",
    "* ✅ **Sentiment Analysis**\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Summary\n",
    "\n",
    "| Step | Description                                                         |\n",
    "| ---- | ------------------------------------------------------------------- |\n",
    "| 1️⃣  | Extract N-grams from text (1 to 4)                                  |\n",
    "| 2️⃣  | Create a vocabulary of unique N-grams                               |\n",
    "| 3️⃣  | Represent sentences as binary vectors (1 if N-gram present, else 0) |\n",
    "| 4️⃣  | Feed vectors into ML/NLP models                                     |\n",
    "\n",
    "> 💡 **In short:**\n",
    "> N-grams represent **text context as numbers**, helping machines learn patterns like humans do.\n",
    "\n",
    "---\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c8d9f0-9a7f-4c79-801e-78f374d77600",
   "metadata": {},
   "source": [
    "#### ***Note: For better Understanding of implementation, refer 12-Bag of words.***\n",
    "> http://localhost:8888/notebooks/Gen%20AI/NLP/Text%20Preprocessing/12-Bag%20of%20Words.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02d1dc-4a0e-42e6-adfa-3425ba3543cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
