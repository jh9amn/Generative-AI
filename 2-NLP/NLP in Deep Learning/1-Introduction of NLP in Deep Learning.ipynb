{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ebcc4a6-9c1b-4e49-86a7-0386811d66b1",
   "metadata": {},
   "source": [
    "## üß† NLP in Deep Learning\n",
    "\n",
    "### Text Data ‚Üí Vectors ‚Üí Numerical Representation\n",
    "Before feeding text data into a neural network, we convert it into numerical form:\n",
    "\n",
    "1. **OHE (One-Hot Encoding)**  \n",
    "2. **BoW (Bag of Words)**  \n",
    "3. **TF-IDF (Term Frequency‚ÄìInverse Document Frequency)**  \n",
    "4. **Word2Vec / AvgWord2Vec** ‚Üí *Used in Sentiment Analysis, Text Classification*\n",
    "\n",
    "---\n",
    "\n",
    "### ü§ñ Artificial Neural Network (ANN)\n",
    "\n",
    "An **Artificial Neural Network** (ANN) is inspired by the human brain.  \n",
    "It consists of **neurons (nodes)** organized in **layers** ‚Äî Input, Hidden, and Output.\n",
    "\n",
    "#### Applications\n",
    "- **Classification** ‚Üí e.g., Sentiment Analysis, Spam Detection  \n",
    "- **Regression** ‚Üí e.g., House Price Prediction  \n",
    "\n",
    "---\n",
    "\n",
    "### Example: House Price Prediction\n",
    "\n",
    "| Feature 1 (f‚ÇÅ) | Feature 2 (f‚ÇÇ) | Target (y) |\n",
    "|----------------|----------------|-------------|\n",
    "| House Size     | No. of Rooms   | Price       |\n",
    "\n",
    "---\n",
    "\n",
    "### üß© Architecture\n",
    "\n",
    "```\n",
    "\n",
    "Input Layer (f‚ÇÅ, f‚ÇÇ)\n",
    "‚Üì\n",
    "Hidden Layer (h‚ÇÅ, h‚ÇÇ)\n",
    "‚Üì\n",
    "Output Layer (≈∑)\n",
    "\n",
    "````\n",
    "\n",
    "Each connection has **weights (W)** and **biases (b)** that are learned during training.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Forward Propagation\n",
    "\n",
    "We calculate the output using:\n",
    "\\[\n",
    "z = W \\cdot x + b\n",
    "\\]\n",
    "\\[\n",
    "a = f(z)\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- `x` ‚Üí input features  \n",
    "- `W` ‚Üí weight matrix  \n",
    "- `b` ‚Üí bias  \n",
    "- `f(z)` ‚Üí activation function (e.g., ReLU, Sigmoid)\n",
    "\n",
    "üëâ The output of one layer becomes the input to the next layer.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Backward Propagation\n",
    "\n",
    "**Goal:** Minimize the loss by updating weights using gradient descent.\n",
    "\n",
    "1. Compute **loss**:\n",
    "   \\[\n",
    "   L = (y - \\hat{y})^2\n",
    "   \\]\n",
    "2. Compute gradient of loss with respect to each weight:\n",
    "   \\[\n",
    "   \\frac{‚àÇL}{‚àÇW}\n",
    "   \\]\n",
    "3. Update weights:\n",
    "   \\[\n",
    "   W_{new} = W_{old} - Œ∑ \\cdot \\frac{‚àÇL}{‚àÇW}\n",
    "   \\]\n",
    "\n",
    "Where `Œ∑` is the **learning rate**.\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ Forward and Backward Propagation Diagram\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "A1[\"Input Layer (x‚ÇÅ, x‚ÇÇ)\"] --> B1[\"Hidden Layer h‚ÇÅ\"]\n",
    "A1 --> B2[\"Hidden Layer h‚ÇÇ\"]\n",
    "B1 --> C[\"Output Layer (≈∑)\"]\n",
    "B2 --> C\n",
    "C --> D[\"Loss Function (y - ≈∑)\"]\n",
    "D --> E[\"Backward Propagation (Gradient Descent)\"]\n",
    "E --> B1\n",
    "E --> B2\n",
    "E --> A1\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Summary\n",
    "\n",
    "| Step | Process                  | Description                                       |\n",
    "| ---- | ------------------------ | ------------------------------------------------- |\n",
    "| 1    | **Forward Propagation**  | Data flows through the network to get predictions |\n",
    "| 2    | **Loss Calculation**     | Compare prediction with actual output             |\n",
    "| 3    | **Backward Propagation** | Adjust weights using gradients                    |\n",
    "| 4    | **Optimization**         | Repeat until loss is minimized                    |\n",
    "\n",
    "---\n",
    "\n",
    "üß† **Key Idea:**\n",
    "Deep learning models like ANN learn patterns automatically by continuously adjusting weights using forward and backward propagation ‚Äî turning numeric vector inputs (from Word2Vec, TF-IDF, etc.) into meaningful predictions for NLP tasks like **sentiment analysis**, **classification**, and **regression**.\n",
    "\n",
    "Perfect üëç ‚Äî you‚Äôre describing how **different data types** (non-sequential, image, sequential) determine which deep learning model (ANN, CNN, RNN) we should use.\n",
    "\n",
    "Here‚Äôs a **complete, clean, and visual Markdown section** explaining this concept ‚Äî including examples and a **graph for sales forecasting** using `mermaid`.\n",
    "You can directly paste this into your `.md` file.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Deep Learning Models and Data Types\n",
    "\n",
    "Different types of data require different neural network architectures.\n",
    "\n",
    "---\n",
    "\n",
    "### 1Ô∏è‚É£ Non-Sequential Data\n",
    "**Order does not matter.**\n",
    "\n",
    "Used when each feature is independent of others.\n",
    "\n",
    "Example:  \n",
    "| Feature | Description |\n",
    "|----------|--------------|\n",
    "| Age | 28 |\n",
    "| Salary | 50,000 |\n",
    "| Experience | 5 years |\n",
    "\n",
    "‚úÖ Suitable Model: **ANN (Artificial Neural Network)**  \n",
    "üìò **Use case:** House Price Prediction, Loan Approval\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Image or Visual Data\n",
    "**Model:** üß† **CNN (Convolutional Neural Network)**\n",
    "\n",
    "CNNs work well with **spatial data** ‚Äî images, video frames, and pixels.\n",
    "\n",
    "üìò **Use cases:**\n",
    "- Image Classification (e.g., Dog vs Cat)\n",
    "- Object Detection (e.g., Detecting pedestrians, cars)\n",
    "- Face Recognition\n",
    "- Medical Imaging\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "\n",
    "Input Image ‚Üí Convolution ‚Üí Pooling ‚Üí Fully Connected ‚Üí Output\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Sequential Data\n",
    "**Order of data matters.**\n",
    "\n",
    "Examples:\n",
    "- Text\n",
    "- Speech\n",
    "- Time-Series\n",
    "- Sentences\n",
    "\n",
    "üìò **Model:** üåÄ **RNN (Recurrent Neural Network)** or **LSTM/GRU**\n",
    "\n",
    "---\n",
    "\n",
    "#### a) Text Generation\n",
    "```\n",
    "\n",
    "Input  ‚Üí  \"This is an apple ___\"\n",
    "Output ‚Üí  \"juice\"\n",
    "\n",
    "```\n",
    "\n",
    "#### b) Chatbot Conversation\n",
    "```\n",
    "\n",
    "Question ‚Üí \"Hi, how are you?\"\n",
    "Answer   ‚Üí \"I'm good, how can I help you?\"\n",
    "\n",
    "```\n",
    "\n",
    "#### c) Language Translation\n",
    "```\n",
    "\n",
    "English ‚Üí \"How are you?\"\n",
    "French  ‚Üí \"Comment √ßa va?\"\n",
    "\n",
    "````\n",
    "\n",
    "#### d) Auto-Suggestion\n",
    "Used in Gmail or LinkedIn:\n",
    "> \"Let's schedule a meeting...\" ‚Üí Auto-complete prediction\n",
    "\n",
    "#### e) Sales Forecasting (Time-Series)\n",
    "Predict future sales from date-wise data.\n",
    "\n",
    "| Date       | Sales |\n",
    "|-------------|--------|\n",
    "| 2025-01-01  | 1200   |\n",
    "| 2025-01-02  | 1300   |\n",
    "| 2025-01-03  | 1400   |\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Graph Representation (Sales Forecasting)\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "A[\"Time-Series Data (Date, Sales)\"] --> B[\"RNN / LSTM Network\"]\n",
    "B --> C[\"Future Sales Prediction\"]\n",
    "C --> D[\"Sales Forecast Curve\"]\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Summary\n",
    "\n",
    "| Data Type                   | Sequence Matters? | Model Used       | Example                            |\n",
    "| --------------------------- | ----------------- | ---------------- | ---------------------------------- |\n",
    "| Tabular Data                | ‚ùå No              | ANN              | House Price Prediction             |\n",
    "| Image / Video               | Spatial (2D)      | CNN              | Image Classification               |\n",
    "| Text / Speech / Time-Series | ‚úÖ Yes             | RNN / LSTM / GRU | Chatbots, Translation, Forecasting |\n",
    "\n",
    "---\n",
    "\n",
    "üß© **Key Insight:**\n",
    "\n",
    "* **ANN** ‚Üí Best for independent features\n",
    "* **CNN** ‚Üí Best for spatial patterns (images/videos)\n",
    "* **RNN/LSTM** ‚Üí Best for sequential or time-based data\n",
    "\n",
    "```\n",
    "\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d8fad-8cf9-4be6-8adf-b66a1bacfc72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
